NumLayers
====

A Deep Learning Library Written in NumPy
----
- A personal project for fun and for the purpose of learning <br>
- Version: 0.5.0 <br><br>
- Author: Wenlin Chen <br>
- E-mail: chen.wenlin@outlook.com <br><br>
23rd December, 2018 <br><br>

Requirements
----
- Python 3.x<br>
- NumPy<br>
- Matplotlib<br>

Features
----
Layers<br>
- Linear<br>
- Convolutional 2D<br>
- Max Pooling 2D<br>
- Batch Normalization 1D<br>
- Batch Normalization 2D<br>
- Dropout<br>

Losses<br>
- Cross Entropy Loss<br>
- Hinge Loss<br>
- Binary Cross Entropy Loss<br>
- Mean Square Error Loss<br>

Activation Functions<br> 
- ReLU<br>
- Leaky ReLU<br>
- Tanh<br>
- Sigmoid<br>

Optimizers<br>
- Stochastic Gradient Descent<br>
- Momentum<br>
- Adam<br>

Training Tools<br>
- Learning Rate Decay<br>
- L2 Regularization<br><br>


Datasets
----
- MNIST<br>
http://yann.lecun.com/exdb/mnist/ <br>
- CIFAR10<br>
https://www.cs.toronto.edu/~kriz/cifar.html <br><br>

Training Curves
----
- mlp_mnist.py<br>
![MLP for MNIST training curve](https://github.com/Wenlin-Chen/NumLayers/blob/master/logs/mlp_mnist.png)<br><br>
- mlp_cifar10.py<br>
![MLP for CIFAR10 training curve](https://github.com/Wenlin-Chen/NumLayers/blob/master/logs/mlp_cifar10.png)
